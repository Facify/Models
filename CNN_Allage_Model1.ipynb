{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-certificate",
   "metadata": {},
   "source": [
    "CNN_Allage_Model for Age detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "related-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D,GlobalAveragePooling2D,Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opening-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/aglined faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(age, number_of_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    folder=path+age+'/'\n",
    "    images=os.listdir(folder)[:number_of_images]\n",
    "    for i in range(number_of_images):\n",
    "        img=mpimg.imread(folder+images[i])\n",
    "        plt.subplot(number_of_images//2, 2, i+1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "visualize_image(\"020\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for folder, _, imgs in os.walk(path):\n",
    "    if folder!=\"face_age\":\n",
    "        for img in imgs:\n",
    "            img_path=folder+'/'+img\n",
    "            image=Image.open(img_path)\n",
    "            image=image.convert('L') #gray-scale images\n",
    "            X.append(np.array(image))\n",
    "            y.append(int(folder[-3:]))\n",
    "\n",
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype(\"float32\")\n",
    "#normalization\n",
    "X /= 255.0\n",
    "y = y//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 200, 200, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=True, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range = 0.2, # random application of shearing\n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True) # randomly flipping half of the images horizontally\n",
    "\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "                                patience=5, # wait for 5 epochs\n",
    "                                min_delta = 0.01, # if in 5 epochs the loss function doesn't increase (for accuracy) \n",
    "                                               # or decrease (for val_loss) by 1%, then stop\n",
    "                                verbose=1, # print the training epoch on which training was stopped\n",
    "                                mode = 'min',\n",
    "                                monitor='val_loss')\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "                                    monitor=\"val_loss\",\n",
    "                                    patience=3, # if val_loss plateaus for 3 epochs such that it doesn't see \n",
    "                                                # an improvement of size = epsilon\n",
    "                                    episilon= 0.01,\n",
    "                                    factor=0.1,  # then we reduce the learning rate by a factor of 0.1\n",
    "                                    cooldown = 4, # and we wait for 4 epochs before we restart again\n",
    "                                    verbose=1)\n",
    "\n",
    "time_callback = TimingCallback()\n",
    "\n",
    "        \n",
    "# hyperparameters\n",
    "lr = 0.01\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "results = {}\n",
    "input_shape =[200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n",
    "                   padding=\"valid\",\n",
    "                   kernel_regularizer=regularizers.l2(0.00001),\n",
    "                   input_shape=(input_shape[0], input_shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation=\"linear\")) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'checkpoints/cnn_face-age__relu.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='models/cnn_facial_age-relu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_datagen.flow(\n",
    "        X_train, y_train,\n",
    "        batch_size = batch_size\n",
    "    ), # use augmented images\n",
    "    validation_data = (X_val, y_val),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [\n",
    "                    reduce_learning_rate,\n",
    "                    early_stopping,\n",
    "                    time_callback,\n",
    "                    checkpoint\n",
    "                ],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_adam_train_loss = model.history.history[\"loss\"]\n",
    "baseline_adam_val_loss = model.history.history[\"val_loss\"]\n",
    "baseline_adam_train_acc = model.history.history[\"mae\"]\n",
    "baseline_adam_val_acc = model.history.history[\"val_mae\"]\n",
    "\n",
    "results[\"baseline_adam\"] = {'train-loss': baseline_adam_train_loss,\n",
    "                             'val-loss': baseline_adam_val_loss,\n",
    "                             'train-mae': baseline_adam_train_acc,\n",
    "                             'val-mae': baseline_adam_val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-mae'])),results[cond]['train-mae'], '-', label=cond+\"_train\", color=\"blue\")\n",
    "    plt.plot(range(len(results[cond]['val-mae'])),results[cond]['val-mae'], '-', label=cond+\"_val\", color=\"green\")\n",
    "plt.title(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "dict(zip(model.metrics_names, model_test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_range=np.round((y_pred), 0).astype(int)\n",
    "float(100*sum(np.equal(y, y_pred_range).astype(int))/len(y_pred_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series((5 * y_pred_range.reshape((len(y_pred))))).plot(kind='hist', bins=40, label='Predicted', alpha=0.5)\n",
    "pd.Series((5 * y)).plot(kind='hist', bins=40, label='Original', alpha=0.5)\n",
    "\n",
    "plt.legend(title='Group')\n",
    "\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.title('Predicted vs Original', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y, y_pred_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
