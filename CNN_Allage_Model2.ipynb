{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D, AveragePooling2D,GlobalAveragePooling2D, GlobalMaxPooling2D,Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/aglined faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(age, number_of_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    folder=path+age+'/'\n",
    "    images=os.listdir(folder)[:number_of_images]\n",
    "    for i in range(number_of_images):\n",
    "        img = cv2.imread(folder+images[i], 0)\n",
    "        \n",
    "#         highThresh, thresh_im = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "#         lowThresh = 0.5*highThresh\n",
    "#         edges = cv2.Canny(img, lowThresh, highThresh)\n",
    "        \n",
    "#         v = np.median(img)\n",
    "#         sigma = 0.33\n",
    "#         lower = int(max(0, (1.0 - sigma) * v))\n",
    "#         upper = int(min(255, (1.0 + sigma) * v))\n",
    "#         edges = cv2.Canny(img, lower, upper)\n",
    "\n",
    "#         plt.subplot(number_of_images//2, 4, 2*i+1),plt.imshow(img, cmap = 'gray')\n",
    "#         plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "#         plt.subplot(number_of_images//2, 4, 2*i+2),plt.imshow(edges, cmap = 'gray')\n",
    "#         plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        plt.subplot(number_of_images//2, 2, i+1),plt.imshow(img, cmap = 'gray')\n",
    "\n",
    "visualize_image(\"16\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for folder, _, imgs in os.walk(path):\n",
    "    if folder!=\"face_age\":\n",
    "        for img in imgs:\n",
    "            img_path=folder+'/'+img\n",
    "            image = cv2.imread(img_path, 0)\n",
    "            \n",
    "#             highThresh, thresh_im = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "#             lowThresh = 0.5*highThresh\n",
    "#             edges = cv2.Canny(image, lowThresh, highThresh)\n",
    "            \n",
    "#             X.append(np.array(edges))\n",
    "            X.append(np.array(image))\n",
    "            y.append(int(folder[-3:]))\n",
    "\n",
    "X=np.array(X)\n",
    "y=np.array(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype(\"float32\")\n",
    "#normalization\n",
    "X /= 255.0\n",
    "y = y//20 #dividing in range of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 200, 200, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y)[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "                                patience=6, # wait for 6 epochs\n",
    "                                min_delta = 0.01, # if in 6 epochs the loss function doesn't increase (for accuracy) \n",
    "                                               # or decrease (for val_loss) by 1%, then stop\n",
    "                                verbose=1, # print the training epoch on which training was stopped\n",
    "                                mode = 'min',\n",
    "                                monitor='val_loss')\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "                                    monitor=\"val_loss\",\n",
    "                                    patience=3, # if val_loss plateaus for 3 epochs such that it doesn't see \n",
    "                                                # an improvement of size = epsilon\n",
    "                                    episilon= 0.01,\n",
    "                                    factor=0.1,  # then we reduce the learning rate by a factor of 0.1\n",
    "                                    cooldown = 4, # and we wait for 4 epochs before we restart again\n",
    "                                    verbose=1)\n",
    "\n",
    "time_callback = TimingCallback()\n",
    "\n",
    "        \n",
    "# hyperparameters\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "results = {}\n",
    "input_shape =[200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './cnn_face-age__relu-softmax_AgeRange-20.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='./cnn_facial_age-relu-softmax_AgeRange-20.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_datagen.flow(\n",
    "        X_train, y_train,\n",
    "        batch_size = batch_size\n",
    "    ), # use augmented images\n",
    "    validation_data = (X_test, y_test),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [\n",
    "                    reduce_learning_rate,\n",
    "                    early_stopping,\n",
    "                    time_callback,\n",
    "                    checkpoint\n",
    "                ],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_adam_train_loss = model.history.history[\"loss\"]\n",
    "baseline_adam_val_loss = model.history.history[\"val_loss\"]\n",
    "baseline_adam_train_acc = model.history.history[\"mae\"]\n",
    "baseline_adam_val_acc = model.history.history[\"val_mae\"]\n",
    "\n",
    "results[\"baseline_adam\"] = {'train-loss': baseline_adam_train_loss,\n",
    "                             'val-loss': baseline_adam_val_loss,\n",
    "                             'train-mae': baseline_adam_train_acc,\n",
    "                             'val-mae': baseline_adam_val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-mae'])),results[cond]['train-mae'], '-', label=cond+\"_train\", color=\"blue\")\n",
    "    plt.plot(range(len(results[cond]['val-mae'])),results[cond]['val-mae'], '-', label=cond+\"_val\", color=\"green\")\n",
    "plt.title(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "dict(zip(model.metrics_names, model_test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series((y_pred)).plot(kind='hist', bins=40, label='Predicted', alpha=0.5)\n",
    "pd.Series(argmax(y_test, axis = 1)).plot(kind='hist', bins=40, label='Original', alpha=0.5)\n",
    "\n",
    "plt.legend(title='Group')\n",
    "\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.title('Predicted vs Original', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(argmax(y_test, axis = 1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(argmax(y_test, axis = 1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-greeting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
